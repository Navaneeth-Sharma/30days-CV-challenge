{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c8ec812-fc86-4ade-89de-0def368eb91b",
   "metadata": {},
   "source": [
    "# Day 1\n",
    "\n",
    "## Opencv Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636e8d72-575a-4a5b-ac5e-7ef687a2268e",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f3dbdb-fd39-4b24-951a-91b4cf8eddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082e7837-43e8-4813-9b0e-64e0fb5cdc4c",
   "metadata": {},
   "source": [
    "### Imread function\n",
    "\n",
    "- cv2.imread(path, flag); # Here path is image path and flag is the kind of image need to parsed\n",
    "- there are majorly 3 flags\n",
    "  - cv2.IMREAD_COLOR (Image -> BGR)\n",
    "  - cv2.IMREAD_GRAYSCALE (Image -> grayscale)\n",
    "  - cv2.IMREAD_UNCHANGED (Image -> Image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d28c3c60-a31e-4847-a23c-88ab7dc5fa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "img = cv2.imread('../images/dog.png', 1) #1 denotes read as color image\n",
    "\n",
    "cv2.imshow('image', img) #to display args-> (title, image)\n",
    "cv2.waitKey() # to wait until the display is not being closed\n",
    "\n",
    "# #It will run continuously until the key press. \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f894be60-eded-4c70-97a5-6bac6bc07df8",
   "metadata": {},
   "source": [
    "### Imwrite in opencv\n",
    "\n",
    "- cv2.imwrite(filename, image)  \n",
    "- Parameters:\n",
    "    - filename: A string representing the file name. The filename must include image format.\n",
    "    - image: It is the image that is to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea2a7030-dc8c-4fbb-ad59-bf41f72c1844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved without any error? True\n"
     ]
    }
   ],
   "source": [
    "status = cv2.imwrite(r'../images/dog_copy.png', img)\n",
    "\n",
    "print(\"Saved without any error?\", status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6e2b6-9246-4213-b265-54ebf7127fe5",
   "metadata": {},
   "source": [
    "### Basic Operartion on Images\n",
    "\n",
    "- Access pixel values and modify them\n",
    "- Access image properties\n",
    "- Split and merge image channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f0db64-a33e-4608-8359-bb2606af8af9",
   "metadata": {},
   "source": [
    "#### Access pixel and modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b72d3378-b290-418f-9716-f1da79ccff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old pixel [102 175 143]\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('../images/dog.png', 1)\n",
    "\n",
    "pixel = img[100, 100]\n",
    "print(\"old pixel\", pixel)\n",
    "\n",
    "new_pixel = np.array([0,0,0]) #this will turn a part of image to blaok\n",
    "img[100:200, 100:200] = new_pixel\n",
    "\n",
    "cv2.imshow('image', img) \n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60de4b4a-45ce-440b-8d5c-c6ea413ab8a7",
   "metadata": {},
   "source": [
    "#### Access to image properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc42de18-113d-4b48-b9fb-5535a546efd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blue 150\n",
      "red 172\n"
     ]
    }
   ],
   "source": [
    "# blue pixels\n",
    "blue = img[500,500,1]\n",
    "print(\"blue\" , blue)\n",
    "\n",
    "# blue pixels\n",
    "red = img[500,500,2]\n",
    "print(\"red\" , red)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cad3a1-8a0d-46b9-bb15-06ae82457aec",
   "metadata": {},
   "source": [
    "#### Splitting and Merging Image Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bdc884-fe43-4a36-bec6-5ba81f4a8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1,g1,r1 = cv2.split(img) #split to b,g,r\n",
    "img = cv2.merge((b1,g1,r1)) #merge b,g,r to image\n",
    "\n",
    "# b,g,r above and below will be same\n",
    "b2 = img[:,:,0]\n",
    "g2 = img[:,:,1]\n",
    "r2 = img[:,:,2]\n",
    "\n",
    "assert np.all(b1==b2)\n",
    "assert np.all(g1==g2)\n",
    "assert np.all(r1==r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceabfaf4-b039-4209-9971-dda5f2ff9397",
   "metadata": {},
   "source": [
    "### Image Rotation \n",
    "\n",
    "Syntax: cv2.rotate( src, rotateCode[, dst] )\n",
    "Parameters:\n",
    "   - src: It is the image to be rotated.\n",
    "   - rotateCode: It is an enum to specify how to rotate the array.Here are some of the possible values :\n",
    "   - cv2.cv2.ROTATE_90_CLOCKWISE\n",
    "   - cv2.ROTATE_180\n",
    "   - cv2.ROTATE_90_COUNTERCLOCKWISE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa60672-9a92-4e4e-a8bd-5cf7070fc9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.rotate(img, cv2.ROTATE_180)\n",
    "\n",
    "cv2.imshow('image', img2) \n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127ab182-d5cc-43f5-b0fc-9eb12e42c6ff",
   "metadata": {},
   "source": [
    "### Draw circle and rectangles \n",
    "\n",
    "Syntax: cv2.circle(image, center_coordinates, radius, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7947cdc-c3a3-40a2-95dc-7a0f528096fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.circle(img, (100,100), 100, (255,0,0), 2)\n",
    "cv2.imshow('image', img) \n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903fd97-87b7-4235-a025-f6b25779adf9",
   "metadata": {},
   "source": [
    "Syntax: cv2.rectangle(image, start_point, end_point, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92a8613-24c0-4430-b5f3-3e3d1fc4e043",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(img, (100,100), (300, 300), (255,0,0), 2)\n",
    "cv2.imshow('image', img) \n",
    "cv2.waitKey() \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f40a398-8287-498f-a855-fdf818e91096",
   "metadata": {},
   "source": [
    "#### Line\n",
    "Syntax: cv2.line(image, start_point, end_point, color, thickness)\n",
    "#### Polylines\n",
    " syntax\n",
    "cv2.polyLine(image, arr, is_closed, color, thickness)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e60c9ca-04e1-455e-ba77-bba91659390b",
   "metadata": {},
   "source": [
    "## Canny Edge Detection\n",
    "Edge detection is an image processing technique used for finding the boundaries of objects within images.Here we will use a popular edge detection algorithm Canny Edge Detection\n",
    "\n",
    "edges = cv2.Canny(img, minVal, maxVal, apertureSize, L2gradient)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7c31370-adab-4322-9351-21105aed0102",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('../images/dog.png', 1)\n",
    "edges = cv2.Canny(img, 100, 200, True)\n",
    "cv2.imshow(\"Edge Detected Image\", edges)  \n",
    "cv2.imshow(\"Original Image\", img)  \n",
    "cv2.waitKey(0)  # waits until a key is pressed  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3857440a-850e-41cd-b30a-780735ec2939",
   "metadata": {},
   "source": [
    "### Image Smoothing\n",
    "- Averaging\n",
    "- Median Blur\n",
    "- Gaussiaan Blur\n",
    "- Bilateral Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6d8c371-91d6-45bd-bf56-676a7ff76520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging\n",
    "# cv2.blur(src, ksize,anchor, borderType)\n",
    "cv2.imshow('Original Image',img)  \n",
    "cv2.imshow('cv2.blur output', cv2.blur(img, (3,3)))  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94c2f0d-eea4-4a8e-9462-d73e9b2fe1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Blur\n",
    "cv2.imshow('cv2.medianBlur output', cv2.medianBlur(img, 5))  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4a316b-3b36-4dac-a2e9-c2d5a674cbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  GaussianBlur(src, dst, ksize, sigmaX,sigmaY)\n",
    "# dst âˆ’ output image of the same size and type as src.\n",
    "\n",
    "cv2.imshow('cv2.GaussianBlur output', cv2.GaussianBlur(img, (5, 5), cv2.BORDER_DEFAULT))     \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4117c9a8-b852-4728-a7da-d6e2ea0bbe84",
   "metadata": {},
   "source": [
    "#### OpenCV Bilateral Filter\n",
    "This method of noise removal is highly effective but is slower compared to other filters.The Gaussian filter blurred the edges too and that is not what we want,but this filter makes sure that only those pixels with similar intensities to the central pixel are considered for blurring,thus preserving the edges since pixels at edges will have large intensity variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8d7ab3-0458-4e70-b584-e44d2332e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('bilateral Image', cv2.bilateralFilter(img,9,75,75))  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f4d0db-9b03-45eb-af65-946bf97d796e",
   "metadata": {},
   "source": [
    "##  Image Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70ad0975-fd93-4d34-8fbc-d26c7eac5326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to convert the image in grayscale  \n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) \n",
    "\n",
    "# cv2.threshold(source, thresholdValue, maxVal, thresholdingTechnique)\n",
    "threshold = 175\n",
    "ret, thresh1 = cv2.threshold(img_gray, threshold, 255, cv2.THRESH_BINARY) \n",
    "\n",
    "cv2.imshow('binarized Image', thresh1)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16516849-275c-4295-845e-9784ccf7da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive thresholding\n",
    "# adaptiveThreshold(src, dst, maxValue, adaptiveMethod, thresholdType, blockSize, C)\n",
    "\n",
    "th2 = cv2.adaptiveThreshold(img_gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "            cv2.THRESH_BINARY,151,12)\n",
    "th3 = cv2.adaptiveThreshold(img_gray,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "            cv2.THRESH_BINARY,101,12)\n",
    "\n",
    "\n",
    "cv2.imshow('binarized Image', th3)  \n",
    "cv2.waitKey(0)  \n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92abd9a0-4d44-4fdf-a946-6ac2c8fb647a",
   "metadata": {},
   "source": [
    "## Video capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7fee42-9aae-4bbf-a617-6cf0cdf042bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # Our operations on the frame come here\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683755ee-599b-4d91-9d25-ce76eac9ec38",
   "metadata": {},
   "source": [
    "Using previous knowledge here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72da9c75-10dd-4415-860e-24cba116853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "cap = cv2.VideoCapture(0)\n",
    " \n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # Our operations on the frame come here\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # adding canny edge detection\n",
    "    # gray = cv2.Canny(gray, 100, 300, True)\n",
    "    # threshold \n",
    "    threshold = 100\n",
    "    ret, thresh1 = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY) \n",
    "    \n",
    " \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',thresh1)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "802040d4-0d84-4ced-919f-f2a874ee705a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
